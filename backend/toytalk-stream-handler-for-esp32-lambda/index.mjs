  // Node.js 18+ / ESMï¼ˆindex.mjsï¼‰
  // Handler: index.handler
  // Env: OPENAI_API_KEY
  import OpenAI from "openai";
  import { createHash } from "node:crypto";

  const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

  // ---- ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®šæ•° ----
  const HEAD_MIN_CHARS = 24;      // ä»Šå›ã¯ä½¿ã‚ãªã„ï¼ˆãƒ˜ãƒƒãƒ‰TTSç„¡åŠ¹ï¼‰
  const SEG_MAX_CHARS  = 48;
  const TTS_FORMAT     = "pcm";
  const VOICE_DEFAULT  = "alloy";
  const DEBUG          = false;
  const DEBUG_TIME     = process.env.DEBUG_TIME === "true";

  const send  = (res, ev, data)=>res.write(`event: ${ev}\ndata: ${JSON.stringify(data)}\n\n`);
  const sha1  = (s)=>createHash("sha1").update(s).digest("hex");

  // ---- é¸æŠãƒ¢ãƒ‡ãƒ«å®šç¾©ï¼ˆã¾ãšã¯ OpenAI å›ºå®šé‹ç”¨ï¼‰----
  const MODEL_DEFAULT = "OpenAI";
  /** å°†æ¥ã®æ‹¡å¼µç”¨ã«ãƒ†ãƒ¼ãƒ–ãƒ«åŒ–ã—ã¦ãŠãï¼ˆä»Šã¯ OpenAI ã ã‘ä½¿ã†ï¼‰ */
  const MODEL_TABLE = {
    // LLM: OpenAI / TTS: OpenAI
    OpenAI: {
      llmVendor: "openai",
      llmModel:  "gpt-4.1-mini",
      ttsVendor: "openai",
      ttsModel:  "gpt-4o-mini-tts",
    },
    // LLM: OpenAI / TTS: Google Cloud Text-to-Speech
    Google: {
      llmVendor: "openai",
      llmModel:  "gpt-4.1-mini",
      ttsVendor: "google",
      ttsModel:  "google-tts",
    },
    // LLM: OpenAI / TTS: Gemini Speech Generation
    Gemini: {
      llmVendor: "openai",
      llmModel:  "gpt-4.1-mini",
      ttsVendor: "gemini",
      ttsModel:  "gemini-2.5-flash-preview-tts",   // åç§°ã¯ä»»æ„ï¼ˆè­˜åˆ¥ç”¨ï¼‰
    },
    // ç½®ãçŸ³
    NijiVoice: {
      llmVendor: "openai",
      llmModel:  "gpt-4.1-mini",
      ttsVendor: "",       // å¾Œã§å¤‰æ›´
      ttsModel:  "",
    },
  };



  // æ–‡æœ«ã‹ã©ã†ã‹ï¼ˆç°¡æ˜“ï¼‰
  function endsWithSentence(s) {
    return /[ã€‚ï¼ï¼Ÿ!?]\s*$/.test(s);
  }

// OpenAI TTS â†’ base64
async function ttsToBase64OpenAI(text, voice, ttsModel) {
  try {
    const tts = await openai.audio.speech.create({
      model: ttsModel,
      input: text,
      voice,
      // ğŸ”½ ã“ã“ã‚’ format ã§ã¯ãªã response_format ã«å¤‰æ›´
      response_format: "pcm"
    });

    const buf = Buffer.from(await tts.arrayBuffer());
    console.log(`[TTS] PCM size: ${buf.length} bytes`);

    // ğŸ”½ å…ˆé ­ãŒ MP3 ã ã£ãŸã‚‰ï¼ˆFF F3 / ID3 ãªã©ï¼‰ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ WAV å†å–å¾—
    if (buf[0] === 0xFF && (buf[1] === 0xF3 || buf[1] === 0xFB || buf[0] === 0x49)) {
      console.warn("[TTS] PCM not returned, retrying as WAV");
      const tts2 = await openai.audio.speech.create({
        model: ttsModel.replace("mini", "tts"), // miniã§å¤±æ•—ã—ãŸã‚‰å¤§ãƒ¢ãƒ‡ãƒ«ã«åˆ‡æ›¿
        input: text,
        voice,
        format: "wav"
      });
      const buf2 = Buffer.from(await tts2.arrayBuffer());
      return buf2.toString("base64");
    }

    // ã“ã“ã¾ã§æ¥ãŸã‚‰æœ¬ç‰©ã®PCM
    return buf.toString("base64");

  } catch (err) {
    console.error("[TTS] OpenAI PCM fetch failed:", err);
    throw err;
  }
}



  // PCM16 (LINEAR16) ã‚’ WAV ã¸ãƒ©ãƒƒãƒ—ã—ã¦ base64 ã‚’è¿”ã™
  function pcm16ToWavBase64(pcmB64, sampleRate = 24000, channels = 1) {
    // å…¥åŠ›: Google TTS ã® LINEAR16 base64ï¼ˆLE, signedï¼‰
    let pcm = Buffer.from(pcmB64, "base64");

    const bytesPerSample = 2;
    const totalSamples = pcm.length / bytesPerSample;

    // --- DCã‚ªãƒ•ã‚»ãƒƒãƒˆé™¤å»ï¼ˆå¹³å‡å€¤ã‚’0ã«å¯„ã›ã‚‹ï¼‰ ---
    let sum = 0;
    for (let i = 0; i < totalSamples; i++) sum += pcm.readInt16LE(i * 2);
    const mean = sum / totalSamples;
    for (let i = 0; i < totalSamples; i++) {
      const v = pcm.readInt16LE(i * 2) - mean;
      pcm.writeInt16LE(Math.max(-32768, Math.min(32767, Math.round(v))), i * 2);
    }

    // --- å…ˆé ­/æœ«å°¾ ã‚’ãƒãƒ‹ãƒ³ã‚°çª“ã§ãƒ•ã‚§ãƒ¼ãƒ‰ï¼ˆGoogle TTSã®å†’é ­ã‚¯ãƒªãƒƒã‚¯éŸ³æ½°ã—ï¼‰ ---
    const fadeMs = 12;
    const fadeSamples = Math.min(
      Math.floor(sampleRate * fadeMs / 1000),
      Math.floor(totalSamples / 4)
    );
    for (let i = 0; i < fadeSamples; i++) {
      const wIn  = 0.5 * (1 - Math.cos(Math.PI * i / fadeSamples));                 // 0â†’1
      const wOut = 0.5 * (1 - Math.cos(Math.PI * (fadeSamples - i) / fadeSamples)); // 1â†’0
      // in
      const vi = pcm.readInt16LE(i * 2);
      pcm.writeInt16LE(Math.round(vi * wIn), i * 2);
      // out
      const idx = (totalSamples - 1 - i) * 2;
      const vo = pcm.readInt16LE(idx);
      pcm.writeInt16LE(Math.round(vo * wOut), idx);
    }

    // --- å…ˆé ­ã®ç„¡éŸ³ãƒ‘ãƒƒãƒ‰ï¼ˆGoogle TTSã®å†’é ­ã‚¯ãƒªãƒƒã‚¯éŸ³å¸åï¼‰---
    const padHeadMs = 40;
    const padSamples = Math.max(1, Math.floor(sampleRate * padHeadMs / 1000));
    const pad = Buffer.alloc(padSamples * bytesPerSample, 0);
    pcm = Buffer.concat([pad, pcm]);

    // --- WAV ãƒ©ãƒƒãƒ— ---
    const byteRate   = sampleRate * channels * 2;
    const blockAlign = channels * 2;
    const dataSize   = pcm.length;
    const headerSize = 44;
    const buf = Buffer.alloc(headerSize + dataSize);
    buf.write("RIFF", 0);
    buf.writeUInt32LE(36 + dataSize, 4);
    buf.write("WAVE", 8);
    buf.write("fmt ", 12);
    buf.writeUInt32LE(16, 16);
    buf.writeUInt16LE(1, 20);
    buf.writeUInt16LE(channels, 22);
    buf.writeUInt32LE(sampleRate, 24);
    buf.writeUInt32LE(byteRate, 28);
    buf.writeUInt16LE(blockAlign, 32);
    buf.writeUInt16LE(16, 34);
    buf.write("data", 36);
    buf.writeUInt32LE(dataSize, 40);
    pcm.copy(buf, 44);
    return buf.toString("base64");
  }

  function resolveGoogleTtsFromBody(body) {
    const t = body?.tts || {};
    // Googleã®voiceå½¢å¼ã ã‘é€šã™ï¼ˆalloyç­‰ãŒå…¥ã£ã¦ã‚‚å®‰å…¨ã«æ—¢å®šã¸ï¼‰
    const cand = t.voice || body?.voice;
    const isGoogleVoice = typeof cand === "string" && /^[a-z]{2}-[A-Z]{2}-/.test(cand);
    const voiceName = isGoogleVoice ? cand : "ja-JP-Neural2-B";

    return {
     voiceName,
     // â† æœªæŒ‡å®šã¯ "å…¥ã‚Œãªã„"ï¼ˆ= undefined ã‚’è¿”ã™ï¼‰
     speakingRate: (typeof t.speakingRate === "number") ? t.speakingRate : undefined,
     pitch:        (typeof t.pitch        === "number") ? t.pitch        : undefined,
     sampleRateHertz: (typeof t.sampleRateHertz === "number") ? t.sampleRateHertz : undefined,
      audioEncoding: "LINEAR16", // â˜… WAVå›ºå®šï¼ˆLINEAR16â†’WAVãƒ©ãƒƒãƒ—ï¼‰
    };
  }

  // Google Cloud Text-to-Speech (API Key) â†’ base64(WAV)
  async function ttsToBase64Google(
    text,
    {
      voiceName,
      speakingRate = 1.3,
      pitch = 3.0,
      sampleRateHertz = 24000,
      audioEncoding = "LINEAR16", // â† WAVã«åŒ…ã‚€å‰æ
    } = {}
  ) {
    const key = process.env.GOOGLE_API_KEY;
    if (!key) throw new Error("GOOGLE_API_KEY is not set");
    // ä¾‹: "ja-JP-Neural2-B" â†’ "ja-JP"
    const parts = String(voiceName).split("-");
    const languageCode = parts.length >= 2 ? `${parts[0]}-${parts[1]}` : "ja-JP";

    const resp = await fetch(
      `https://texttospeech.googleapis.com/v1/text:synthesize?key=${key}`,
      {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          input: { text },
          voice: { languageCode, name: voiceName },
          audioConfig: {
            audioEncoding,
            speakingRate,
            pitch,
            sampleRateHertz,
          },
        }),
      }
    );
    const json = await resp.json();
    if (!resp.ok) {
      const msg = json?.error?.message || "Google TTS failed";
      throw new Error(msg);
    }
    // json.audioContent ã¯ PCM16 (raw)ã€‚â†’ WAV ã«åŒ…ã‚“ã§è¿”ã™
    console.log("TTS Content-Type:", tts.headers.get("content-type"));
    return pcm16ToWavBase64(json.audioContent, sampleRateHertz, 1);
    console.log("TTS Content-Type:", tts.headers.get("content-type"));
  }


  // Gemini ç”¨ã® voice è§£æ±ºï¼ˆã‚¢ãƒ—ãƒªã‹ã‚‰ "Lede"/"Puck" ãªã©ãŒæ¥ã‚‹æƒ³å®šï¼‰
  function resolveGeminiTtsFromBody(body, cfg) {
    const t = body?.tts || {};
    const cand = t.voice || body?.voice;
    const looksGoogle = typeof cand === "string" && /^[a-z]{2}-[A-Z]{2}-/.test(cand);
    const looksGemini = typeof cand === "string"
      && /^[A-Za-z][A-Za-z0-9_-]{1,40}$/.test(cand)   // è‹±æ•°/ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢/ãƒã‚¤ãƒ•ãƒ³å¯
      && !looksGoogle;                                 // Google å½¢å¼ã¯é™¤å¤–
    const voiceName = looksGemini ? cand : "leda";     // æ—¢å®šã¯ Koreï¼ˆLede/Puck ç­‰ã§ã‚‚OKï¼‰
    return { model: cfg.ttsModel, voiceName };
  }

  // Gemini Speech Generation â†’ base64(WAV)ï¼ˆAPIã‚­ãƒ¼ã¯ GOOGLE_API_KEY ã‚’å…±ç”¨ï¼‰
  async function ttsToBase64Gemini(text, { model = "gemini-2.5-flash-preview-tts", voiceName = "Kore" } = {}) {
    const key = process.env.GOOGLE_API_KEY;
    if (!key) throw new Error("GOOGLE_API_KEY is not set");
    const resp = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/${encodeURIComponent(model)}:generateContent`,
      {
        method: "POST",
        headers: { "x-goog-api-key": key, "Content-Type": "application/json" },
        body: JSON.stringify({
          contents: [{ parts: [{ text }] }],
          generationConfig: {
            responseModalities: ["AUDIO"],
            speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName } } },
          },
          model,
        }),
      }
    );
    const json = await resp.json();
    if (!resp.ok) throw new Error(json?.error?.message || "Gemini TTS failed");
    const b64Pcm = json?.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data || "";
    if (!b64Pcm) throw new Error("Gemini TTS: empty audio");
    // 24kHz/mono PCM16 â†’ æ—¢å­˜ã® WAV ãƒ©ãƒƒãƒ‘ã§åŒ…ã‚€
    return pcm16ToWavBase64(b64Pcm, 24000, 1);
  }


  
  export const handler = awslambda.streamifyResponse(async (event, res) => {
    res.setContentType("text/event-stream");

    const body    = event.body ? JSON.parse(event.body) : {};
    const voice   = body.voice ?? VOICE_DEFAULT;
    const messages= body.messages ?? [{ role:"user", content:"è‡ªå·±ç´¹ä»‹ã—ã¦" }];
    const rawModel = typeof body.model === "string" ? body.model : undefined;
    const modelKey = normalizeModelKey(rawModel) ?? MODEL_DEFAULT;
    const cfg      = MODEL_TABLE[modelKey] ?? MODEL_TABLE[MODEL_DEFAULT];

    function normalizeModelKey(k) {
      if (!k) return undefined;
      const s = String(k).toLowerCase();
      if (s.includes("openai"))  return "OpenAI";
      if (s.includes("google"))  return "Google";
      if (s.includes("gemini"))  return "Gemini";
      if (s.includes("niji"))    return "NijiVoice";
      return undefined; // ä¸æ˜ãªã‚‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    }


    // ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã®è¨ˆæ¸¬ãƒ»ãƒ‡ãƒãƒƒã‚°ç”¨ã«ã€Œæ¡ç”¨ãƒ¢ãƒ‡ãƒ«ã€ã‚’é€šçŸ¥
    send(res, "mark", { k: "model", v: modelKey });
    send(res, "mark", { k: "llm_vendor", v: cfg.llmVendor });
    send(res, "mark", { k: "tts_vendor", v: cfg.ttsVendor });

    // ã‚µãƒ¼ãƒåŸºæº–æ™‚åˆ»ï¼ˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒREQ_TTFBã‚„LLM/TTSã¨ã®ç›¸å¯¾ã‚’å–ã‚Œã‚‹ï¼‰
    if (DEBUG_TIME) {
      send(res, "ping", { t: Date.now() });
    }

    // ---- LLM é–‹å§‹ ----
    if (DEBUG_TIME) {
      send(res, "mark", { k: "llm_start", t: Date.now() });
    }

    // ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ ï¼ˆä¼šè©±å±¥æ­´ãŒã‚ã‚‹å ´åˆã¯æŒ¨æ‹¶ã‚’çœç•¥ï¼‰
    const systemPrompt = {
      role: "system",
      content: "ã‚ãªãŸã¯å­ä¾›å‘ã‘ã®å‹å¥½çš„ãªéŸ³å£°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ç°¡æ½”ã«ç­”ãˆã¦ã€è‡ªç„¶ã«ä¼šè©±ã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚"
    };
    const messagesWithSystem = [systemPrompt, ...messages];

    let llmStream;
    if (cfg.llmVendor === "openai") {
      const llm = await openai.chat.completions.create({
        model: cfg.llmModel,
        temperature: 0.7,
        stream: true,
        messages: messagesWithSystem,
      });
      llmStream = (async function* () {
        for await (const chunk of llm) {
          const delta = chunk.choices?.[0]?.delta?.content ?? "";
          if (delta) yield delta;
        }
      })();
    } else {
    // ã‚‚ã—å°†æ¥ Gemini LLM ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ãªã‚‰ã“ã“ã§å®Ÿè£…
    const fallback = "ï¼ˆLLM ãƒ«ãƒ¼ãƒˆæœªå®Ÿè£…ã§ã™ï¼‰";
    llmStream = (async function* () { yield fallback; })();
  }

    // ---- ã‚¹ãƒˆãƒªãƒ¼ãƒ çŠ¶æ…‹ ----
    let buf = "";                 // â˜…ã“ã“ã§1å›ã ã‘å®£è¨€
    let textAll = "";
    let segSeq = 0;
    let lastSegHash = "";
    let firstTtsMarked = false;
    let ttsChain = Promise.resolve();


    // segment ã‚’é€ã‚‹å”¯ä¸€ã®çµŒè·¯
    async function emitSegment(text, { final=false } = {}) {
      const t = String(text ?? "").trim();
      if (!t) return;
      const h = sha1(t);
      if (h === lastSegHash) return;     // åŒä¸€æ–‡ã¯å†é€ã—ãªã„
      lastSegHash = h;
      segSeq += 1;

      // ç”»é¢ç”¨ã®ç¢ºå®šãƒ†ã‚­ã‚¹ãƒˆ
      send(res, "segment", { id: segSeq, text: t, final });

      // ---- TTS é–‹å§‹ãƒãƒ¼ã‚¯ï¼ˆæœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ã®ã¿ï¼‰
      if (DEBUG_TIME && !firstTtsMarked) {
        send(res, "mark", { k: "tts_first_byte", t: Date.now() });
        firstTtsMarked = true;
      }

      // éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ï¼ˆtextã¯è¼‰ã›ãªã„ï¼‰
      try {
        let b64, fmt;
        if (cfg.ttsVendor === "openai") {
          b64 = await ttsToBase64OpenAI(t, voice, cfg.ttsModel);
          fmt = TTS_FORMAT;
        } else if (cfg.ttsVendor === "google") {
          const g = resolveGoogleTtsFromBody(body);
          const w = await ttsToBase64Google(t, g);
          b64 = w;
          fmt = "wav";
        } else if (cfg.ttsVendor === "gemini") {
          const g = resolveGeminiTtsFromBody(body, cfg);
          b64 = await ttsToBase64Gemini(t, g);
          fmt = "wav";
        } else {
          throw new Error("Unknown ttsVendor");
        }
        send(res, "tts", { id: segSeq, format: fmt, b64 });
        console.log(`[Lambda] id=${segSeq}, b64.length=${b64?.length ?? 0}, text="${t}"`);
      } catch (e) {
        send(res, "error", { message: `TTS failed: ${e?.message || e}` });
      }
    }

    // ---- LLM ã‚¹ãƒˆãƒªãƒ¼ãƒ å‡¦ç†ï¼ˆå…±é€šã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰----
    try {
      // ---- LLM ã‚¹ãƒˆãƒªãƒ¼ãƒ å‡¦ç†ï¼ˆå…±é€šï¼‰----
      for await (const delta of llmStream) {
        textAll += delta;
        buf     += delta;
        if (DEBUG) send(res, "llm_token", { token: delta });
        if (endsWithSentence(buf) || buf.trim().length >= SEG_MAX_CHARS) {
          const segText = buf.trim();
          buf = "";
          await emitSegment(segText);
        }
      }
      // æ®‹ã‚Š
      const tail = buf.trim();
      if (tail.length > 0) {
        buf = "";
        await emitSegment(tail, { final: true });
      }
      send(res, "done", {});
    } catch (err) {
      const msg = (err && err.message) ? err.message : String(err);
      send(res, "error", { message: msg });
    } finally {
      res.end();
    }
  });
