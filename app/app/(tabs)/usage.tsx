// usage.tsx
import { SafeAreaView, View, Button, StyleSheet, Text } from "react-native";
import { useState, useRef } from "react";
import * as FileSystem from "expo-file-system";
import AudioRecord from "react-native-audio-record";
import { Audio, InterruptionModeIOS } from "expo-av";

export default function Usage() {
  const [filePath, setFilePath] = useState<string | null>(null);
  const soundRef = useRef<Audio.Sound | null>(null);

  // éŒ²éŸ³åˆæœŸåŒ–ï¼ˆåˆå›ã®ã¿ï¼‰
  const initRecording = () => {
    AudioRecord.init({
      sampleRate: 16000,
      channels: 1,
      bitsPerSample: 16,
      wavFile: "test.wav",
    });
  };

  // éŒ²éŸ³é–‹å§‹
  const startRecording = () => {
    setFilePath(null);
    initRecording();
    AudioRecord.start();
    console.log("ğŸ™ï¸ Recording started");
  };

  // éŒ²éŸ³åœæ­¢
  const stopRecording = async () => {
    const raw = await AudioRecord.stop();
    console.log("ğŸ›‘ Recording stopped, raw path:", raw);
    if (!raw) return;
    const uri = raw.startsWith("file://") ? raw : "file://" + raw;

    // æ›¸ãå‡ºã—å®Œäº†å¾…ã¡
    let info = { exists: false, size: 0 };
    for (let i = 0; i < 5; i++) {
      info = await FileSystem.getInfoAsync(uri);
      if (info.exists && (info.size ?? 0) > 0) break;
      await new Promise((r) => setTimeout(r, 50));
    }

    setFilePath(uri);
    console.log("âœ… File ready:", uri);
  };

  // å†ç”Ÿ
  const playRecording = async () => {
    if (!filePath) return;

    // ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒªã‚»ãƒƒãƒˆ
    await Audio.setIsEnabledAsync(false);
    await Audio.setIsEnabledAsync(true);


    // Playbackãƒ¢ãƒ¼ãƒ‰ã¸åˆ‡æ›¿
    //await Audio.setAudioModeAsync({ allowsRecordingIOS: false });ã€€â†ã“ã‚Œã ã¨ã†ã¾ãã„ã‹ãªã„
    await Audio.setAudioModeAsync({
      allowsRecordingIOS: false,
      playsInSilentModeIOS: true,
      staysActiveInBackground: false,
      interruptionModeIOS: InterruptionModeIOS.DoNotMix,
    });



    // å¤ã„éŸ³å£°ã‚’è§£æ”¾
    if (soundRef.current) {
      await soundRef.current.unloadAsync();
      soundRef.current = null;
    }

    // å†ç”Ÿ
    const { sound } = await Audio.Sound.createAsync({ uri: filePath });
    soundRef.current = sound;
    await sound.playAsync();
    console.log("ğŸ”Š Playing:", filePath);
  };

  return (
    <SafeAreaView style={s.root}>
      <View style={s.wrap}>
        <Text style={s.title}>â€»STTæ”¹å–„ã®ãŸã‚ã®ä¸€æ™‚çš„ãªæ¤œè¨¼ä¸­</Text>
        <Button title="éŒ²éŸ³é–‹å§‹" onPress={startRecording} />
        <Button title="éŒ²éŸ³åœæ­¢" onPress={stopRecording} />
        <Button title="å†ç”Ÿ" onPress={playRecording} disabled={!filePath} />
        <Button
          title="ğŸ”„ Force Playback"
          onPress={async () => {
            await Audio.setAudioModeAsync({
              allowsRecordingIOS: false,
              playsInSilentModeIOS: true,
              staysActiveInBackground: false,
              interruptionModeIOS: InterruptionModeIOS.DoNotMix,
            });
            console.log("ğŸ”„ å¼·åˆ¶Playbackåˆ‡æ›¿");
          }}
        />
      </View>
    </SafeAreaView>
  );
}

const s = StyleSheet.create({
  root: { flex: 1, backgroundColor: "#fff" },
  wrap: { padding: 20, gap: 12 },
});
